
# Overview

> This is the official repo for the paper: [NÜWA: Visual Synthesis Pre-training for Neural visUal World creAtion](https://arxiv.org/abs/2111.12417).

![Overview](assets/overview.gif)

NÜWA is a unified multimodal pre-trained model that can **generate new** or **manipulate existing** visual data (i.e., **images and videos**) for **8** visual synthesis tasks (as shown above).

# Samples
## Text-To-Image (T2I)
![t2i](assets/t2i.png)

## SKetch-to-Image (S2I)
![s2i](assets/s2i.png)

## Image Completion (I2I)
![i2i](assets/i2i.png)

## Text-Guided Image Manipulation (TI2I)
![ti2i](assets/ti2i.png)

## Text-to-Video(T2V)
![t2v](assets/t2v.gif)

## Video Prediction (V2V)
![v2v](assets/v2v.gif)

## Sketch-to-Video (S2V)
![s2v](assets/s2v.gif)

## Text-Guided Video Manipulation (TV2V)
![out_final](assets/tv2v.gif)

